# 学习时候的一些疑惑


### 1. 写了model.eval() 为什么还要关闭梯度计算 with torch.no_grad()

某些层在训练和推理时的行为不同，model.eval()会修改这些层的内部状态：

Dropout 层：训练时随机丢弃神经元（防止过拟合），推理时保留所有神经元（输出确定值）。

BatchNorm 层：训练时使用当前批次的统计量（均值、方差），推理时使用全局统计量（已保存的 running_mean/running_var）。

RNN 层：部分 RNN 变体（如 LSTM）在训练时可能启用 dropout，推理时关闭。

总结：model.train() 和model.eval() 不影响模型变量积累梯度

### 2. metric = evaluate.load("glue", "mrpc") 怎么理解

metric = evaluate.load("glue", "mrpc") 并非加载数据集，而是加载与 GLUE 基准测试中 MRPC 任务相关的评估指标（Metric）是一组计算逻辑，用于衡量模型预测结果与真实标签的匹配程度（如计算predictions和references的准确率）。

加载 MRPC 任务的评估指标
GLUE：通用语言理解评估基准（General Language Understanding Evaluation），包含多个 NLP 任务（如 MRPC、MNLI 等）。
MRPC：微软研究释义语料库（Microsoft Research Paraphrase Corpus），任务为判断两个句子是否为释义（二分类任务）。
对应指标：MRPC 任务的官方评估指标是准确率（Accuracy）和F1 分数（F1-Score）。

### 3. range(num_training_steps) 返回的是range对象还是int整数

range(num_training_steps) 返回的是一个 range 对象，而非单个整数。

```python
num_training_steps = 5
r = range(num_training_steps)

print(type(r))        # 输出: <class 'range'>
print(list(r))        # 输出: [0, 1, 2, 3, 4]
print(r.start)        # 输出: 0
print(r.stop)         # 输出: 5
print(r.step)         # 输出: 1
```

### 4. epochs=3是遍历三遍训练集

### 5. adam和sgd区别

使用优化器来更新模型参数的时候，怎么更新是有说法的

sgd: 模型参数=当前参数- 学习率*一个batch积累的梯度

adam：根据参数的梯度历史动态调整每个参数的学习率

速度 vs 稳定性：Adam 适合快速迭代和探索，SGD 适合追求极致泛化能力。

默认选择：对于大多数深度学习任务，优先尝试 Adam 或 AdamW。

精细调优：若时间允许，SGD+Momentum 在某些任务上可能达到更好的最终性能。