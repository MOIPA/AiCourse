{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_blobs\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 设置随机种子\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 生成 2D 数据集（3个簇）\n",
    "X, _ = make_blobs(n_samples=300, centers=3, cluster_std=1.0, random_state=42)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "# 可视化生成的数据\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.title(\"Generated Data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, n_components, n_features):\n",
    "        self.n_components = n_components  # 高斯分量数量\n",
    "        self.n_features = n_features      # 每个样本的特征维度\n",
    "\n",
    "        # 初始化参数（均值、协方差、混合系数）\n",
    "        self.means = torch.randn(n_components, n_features, requires_grad=True)  # 均值\n",
    "        self.covariances = torch.eye(n_features).repeat(n_components, 1, 1)  # 协方差矩阵\n",
    "        self.weights = torch.ones(n_components) / n_components  # 混合系数\n",
    "\n",
    "    def gaussian(self, X, mean, cov):\n",
    "        \"\"\"计算多变量高斯分布的概率密度函数\"\"\"\n",
    "        det = torch.det(cov)\n",
    "        inv_cov = torch.inverse(cov)\n",
    "        norm_factor = torch.sqrt((2 * torch.pi) ** X.shape[1] * det)\n",
    "\n",
    "        # 计算 (x - μ) * Σ⁻¹ * (x - μ).T\n",
    "        diff = X - mean\n",
    "        exponent = -0.5 * torch.sum(diff @ inv_cov * diff, dim=1)\n",
    "\n",
    "        return torch.exp(exponent) / norm_factor\n",
    "\n",
    "    def E_step(self, X):\n",
    "        \"\"\"E 步：计算每个样本属于各个高斯分量的概率（后验概率）\"\"\"\n",
    "        responsibilities = []\n",
    "        for k in range(self.n_components):\n",
    "            prob = self.weights[k] * self.gaussian(X, self.means[k], self.covariances[k])\n",
    "            responsibilities.append(prob.unsqueeze(1))\n",
    "\n",
    "        responsibilities = torch.cat(responsibilities, dim=1)\n",
    "        responsibilities = responsibilities / responsibilities.sum(dim=1, keepdim=True)\n",
    "        return responsibilities\n",
    "\n",
    "    def M_step(self, X, responsibilities):\n",
    "        \"\"\"M 步：更新均值、协方差和混合系数\"\"\"\n",
    "        Nk = responsibilities.sum(dim=0)  # 每个分量的有效样本数\n",
    "\n",
    "        # 更新均值\n",
    "        self.means = (responsibilities.T @ X) / Nk.unsqueeze(1)\n",
    "\n",
    "        # 更新协方差\n",
    "        for k in range(self.n_components):\n",
    "            diff = X - self.means[k]\n",
    "            cov = (responsibilities[:, k].unsqueeze(1) * diff).T @ diff / Nk[k]\n",
    "            self.covariances[k] = cov\n",
    "\n",
    "        # 更新混合系数\n",
    "        self.weights = Nk / X.shape[0]\n",
    "\n",
    "    def fit(self, X, n_iters=100):\n",
    "        \"\"\"EM 训练过程\"\"\"\n",
    "        for i in range(n_iters):\n",
    "            # E步\n",
    "            responsibilities = self.E_step(X)\n",
    "\n",
    "            # M步\n",
    "            self.M_step(X, responsibilities)\n",
    "\n",
    "            # 打印每轮迭代的均值\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Iteration {i+1}: Means = {self.means.detach().numpy()}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"预测每个样本的类别\"\"\"\n",
    "        responsibilities = self.E_step(X)\n",
    "        return torch.argmax(responsibilities, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 GMM 模型\n",
    "n_components = 3  # 分量数量\n",
    "n_features = 2    # 特征维度\n",
    "gmm = GMM(n_components, n_features)\n",
    "\n",
    "# 训练 GMM 模型\n",
    "gmm.fit(X, n_iters=100)\n",
    "\n",
    "# 预测每个样本的类别\n",
    "labels = gmm.predict(X)\n",
    "\n",
    "# 可视化聚类结果\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels)\n",
    "plt.title(\"GMM Clustering Result\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
