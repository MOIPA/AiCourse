{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython import display\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size = 256\n",
    "train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展平每个图片，变为长度784的向量，每个分量都是灰度值，因为我们数据集有10个类别，所以输出维度是10\n",
    "\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "W = torch.normal(0,0.01,(num_inputs,num_outputs),requires_grad=True)\n",
    "b = torch.zeros(num_outputs,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现softmax操作\n",
    "# 这里的X不再是个行向量，是个矩阵，每行代表一个样本的输出结果，10列\n",
    "def softmax(X):\n",
    "    X_exp = torch.exp(X) # 张量的每个分量做了e^x\n",
    "    partition = X_exp.sum(dim=1,keepdim=True) # 按列相加，得到每个样本的总e^x和\n",
    "    return X_exp/partition  # 广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现softmax模型\n",
    "# X为 256个图片 * 784灰度值的矩阵，结果是256*10的矩阵\n",
    "def net(X):\n",
    "    return softmax(torch.matmul(X,W)+b)   # +b是利用了广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.5000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一个列表可以作为另一个列表的索引\n",
    "y_hat = torch.tensor([[0.1,0.3,0.6],[0.3,0.2,0.5]])\n",
    "y_hat[[0,1],[0,2]] # 表示取 0,0  和 1,2 坐标的数据，就是（x,y)坐标数据，第一个入参是x的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现交叉熵损失函数 -log(y_hat对应y中正确的)  y向量的长度对应y_hat的行数，y的每一个分量值对应某一行的列坐标\n",
    "def cross_entropy(y_hat,y):\n",
    "    return -torch.log(y_hat[range(len(y_hat),y)]) \n",
    "# 根据上面cell的原理，256行每一行都存在对应一个真实结果，所以x有0,1...255\n",
    "# 对应的y则去匹配x行的某一列，且y是256*1的向量，如果y是 3,1,0,4,0,9.. 那么结果是(0,3),(1,1),(2,0),(3,4).....的y_hat结果向量\n",
    "# 返回256*1的损失结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测值和真实值比较，得到正确判断的数量\n",
    "def accuracy(y_hat,y):\n",
    "    if len(y_hat.shape)>1 and len(y_hat.shape[1])>1: # 如果大于一行且大于1列\n",
    "        y_hat = y_hat.argmax(axis=1) # 每一行都得到最大值的那个列下标，比如第一行最大值在第三列，结果就是y_hat[0]=3，意思是第一个样本预测值为3\n",
    "    cmp = y_hat.type(y.dtype)==y  #y_hat转成y的数据类型，并且比较两个向量，得到一个都是 true,false组成的张量\n",
    "    return float(cmp.type(y.dtype).sum())  # true代表1，sum()会把所有true求和"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
