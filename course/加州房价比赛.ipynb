{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from d2l import torch as d2l\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "# from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载下载的数据集\n",
    "train_data = pd.read_csv('../california-house-prices/train.csv')\n",
    "test_data = pd.read_csv('../california-house-prices/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Address', 'Summary', 'Type', 'Heating', 'Cooling', 'Parking',\n",
      "       'Bedrooms', 'Region', 'Elementary School', 'Middle School',\n",
      "       'High School', 'Flooring', 'Heating features', 'Cooling features',\n",
      "       'Appliances included', 'Laundry features', 'Parking features',\n",
      "       'Listed On', 'Last Sold On', 'City', 'State'],\n",
      "      dtype='object')\n",
      "State                      2\n",
      "Type                     158\n",
      "Bedrooms                 264\n",
      "Cooling features         311\n",
      "Middle School            488\n",
      "Cooling                  540\n",
      "High School              630\n",
      "City                     929\n",
      "Region                   949\n",
      "Heating features        1121\n",
      "Flooring                1347\n",
      "Elementary School       1717\n",
      "Heating                 1859\n",
      "Laundry features        1975\n",
      "Listed On               2467\n",
      "Appliances included     4583\n",
      "Parking features        4959\n",
      "Parking                 5112\n",
      "Last Sold On            6113\n",
      "Summary                46787\n",
      "Address                47325\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 打印类型为非数值的每列有多少个不同值，因为one-hot编码不能对太多不同值编码\n",
    "non_numeric_columns = train_data.select_dtypes(exclude=['number'])\n",
    "print(non_numeric_columns.columns)  # 有21列是字符类型或者是字符和数字混合列\n",
    "unique_counts = non_numeric_columns.apply(pd.Series.nunique).sort_values()\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数，用于判断列中是否包含多种数据类型\n",
    "def is_mixed_type(col):\n",
    "    # 通过 set 保存每列中唯一的数据类型\n",
    "    return len(set(col.apply(type))) > 1\n",
    "\n",
    "# 找出混合列\n",
    "mixed_columns = non_numeric_columns.apply(is_mixed_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到混合列和纯字符列，混合列需要看看哪些能成为数字列，字符列要看看哪些种类少可以做one-hot\n",
    "# print(mixed_columns[mixed_columns])  # 混合类型\n",
    "# print(train_data[mixed_columns[mixed_columns].index].iloc[:4,:])\n",
    "mixed_columns_data = train_data[mixed_columns[mixed_columns].index]\n",
    "string_column_data = train_data[mixed_columns[mixed_columns==False].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State            2\n",
      "Type           158\n",
      "City           929\n",
      "Listed On     2467\n",
      "Address      47325\n",
      "dtype: int64\n",
      "Index(['Summary', 'Heating', 'Cooling', 'Parking', 'Bedrooms', 'Region',\n",
      "       'Elementary School', 'Middle School', 'High School', 'Flooring',\n",
      "       'Heating features', 'Cooling features', 'Appliances included',\n",
      "       'Laundry features', 'Parking features', 'Last Sold On'],\n",
      "      dtype='object')\n",
      "6113\n"
     ]
    }
   ],
   "source": [
    "unique_counts = string_column_data.apply(pd.Series.nunique).sort_values()\n",
    "print(unique_counts)\n",
    "# 保留State字段其他都太大了不好做one-hot，type字段可以做标签编码\n",
    "print(mixed_columns[mixed_columns].index)\n",
    "print(train_data['Last Sold On'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47439, 18)\n",
      "(31626, 18)\n",
      "37951\n",
      "(47439,)\n"
     ]
    }
   ],
   "source": [
    "def pre_process(data):\n",
    "    numeric_colmnu_name = data.select_dtypes(include='number')\n",
    "    if 'Sold Price' in numeric_colmnu_name.columns:\n",
    "        numeric_colmnu_name = numeric_colmnu_name.drop('Sold Price',axis=1)\n",
    "    new_data = data[numeric_colmnu_name.columns]\n",
    "    # 混合列中对Cooling,Heating进行标签编码\n",
    "    if 'Cooling' in data.columns:\n",
    "        col,unique = pd.factorize(data['Cooling'])\n",
    "        col_series = pd.Series(col, name='Cooling_encoded')\n",
    "        new_data = pd.concat([new_data,col_series],axis=1) # 列相加\n",
    "    if 'Heating' in data.columns:\n",
    "        col,unique = pd.factorize(data['Heating'])\n",
    "        col_series = pd.Series(col, name='Heating_encoded')\n",
    "        new_data = pd.concat([new_data,col_series],axis=1) # 列相加\n",
    "    if 'State' in data.columns:\n",
    "        new_data = pd.concat([pd.get_dummies(data['State'],dummy_na=True),new_data],axis=1)\n",
    "    if 'Bedrooms' in data.columns:\n",
    "        bedrooms = pd.to_numeric(data['Bedrooms'], errors='coerce').fillna(0) # 混合列，字符串转为Nan再转0\n",
    "        new_data = pd.concat([new_data,bedrooms],axis=1) \n",
    "    if 'Id' in new_data.columns:\n",
    "        new_data = new_data.drop('Id',axis=1)\n",
    "\n",
    "    if 'Lot' in new_data.columns:\n",
    "        new_data = new_data.drop('Lot',axis=1)\n",
    "    if 'Total interior livable area' in new_data.columns:\n",
    "        new_data = new_data.drop('Total interior livable area',axis=1)\n",
    "    if 'Zip' in new_data.columns:\n",
    "        new_data = new_data.drop('Zip',axis=1)\n",
    "    if 'Annual tax amount' in new_data.columns:\n",
    "        new_data = new_data.drop('Annual tax amount',axis=1)\n",
    "    if 'nan' in new_data.columns:\n",
    "        new_data = new_data.drop('nan',axis=1)\n",
    "    if 'Garage spaces' in new_data.columns:\n",
    "        new_data = new_data.drop('Garage spaces',axis=1)\n",
    "    if 'Tax assessed value' in new_data.columns:\n",
    "        new_data = new_data.drop('Tax assessed value',axis=1)\n",
    "               \n",
    "    return new_data\n",
    "\n",
    "y = train_data['Sold Price']\n",
    "train_data = pre_process(train_data)\n",
    "valid_data = pre_process(test_data)\n",
    "\n",
    "train_data = train_data.apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "valid_data = valid_data.apply(\n",
    "    lambda x: (x-x.mean())/(x.std()))\n",
    "X = train_data.fillna(0)\n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(int(X.shape[0]*0.8))\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([                        'AZ',                         'CA',\n",
      "                                nan,                 'Year built',\n",
      "                        'Bathrooms',             'Full bathrooms',\n",
      "                     'Total spaces',    'Elementary School Score',\n",
      "       'Elementary School Distance',        'Middle School Score',\n",
      "           'Middle School Distance',          'High School Score',\n",
      "             'High School Distance',               'Listed Price',\n",
      "                  'Last Sold Price',            'Cooling_encoded',\n",
      "                  'Heating_encoded',                   'Bedrooms'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 划分数据，train_data 80%作为训练 20%作为验证\n",
    "# 一般使用train_test_split来自sklearn自动划分，这里我手动划分\n",
    "scale = 0.8\n",
    "batch_size = 256 # 每批次256个数据 训练总数居37951 大概要148批次全部获取完\n",
    "epochs = 150\n",
    "split_index = int(X.shape[0] * scale)\n",
    "# 使用 split_index 来切分数据集\n",
    "X_train, X_test = X.iloc[:split_index, :], X.iloc[split_index:, :]\n",
    "y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "# 转为张量\n",
    "X_train = torch.tensor(X_train.values,dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test.values,dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values,dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values,dtype=torch.float32)\n",
    "# 转为迭代器，小批次获取\n",
    "train_dataset = data.TensorDataset(X_train,y_train)  # 封装数据和标签\n",
    "test_dataset = data.TensorDataset(X_test,y_test)\n",
    "train_dataset = data.DataLoader(train_dataset,batch_size,shuffle=True)\n",
    "test_dataset = data.DataLoader(test_dataset,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "数据预处理完成，开始训练和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr,weight_decay = 5,0.001\n",
    "# 均方损失函数\n",
    "loss = nn.MSELoss()\n",
    "# 定义维度\n",
    "num_inputs = train_data.shape[1]  # 输入的是25维\n",
    "# 定义一层神经网络，输出维度是1\n",
    "net = nn.Sequential(nn.Linear(num_inputs,1))\n",
    "# 计算模型的预测值和真实值的对数均方根误差\n",
    "def log_rmse(net, features, labels):\n",
    "    # 为了在取对数时进一步稳定该值，将小于1的值设置为1\n",
    "    clipped_preds = torch.clamp(net(features), 1, float('inf')) # clamp设定最小值为1，因为计算log 0是负无穷，上限是inf正无穷\n",
    "    rmse = torch.sqrt(loss(torch.log(clipped_preds),\n",
    "                           torch.log(labels)))\n",
    "    return rmse.item()  # 返回标量值\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr,weight_decay = weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,loss,train_iter,test_iter,num_epochs,optimizer):\n",
    "    # 转到gpu\n",
    "    net.to(torch.device('cuda'))\n",
    "    train_ls, test_ls = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        for X,y in train_iter:\n",
    "            X.to(torch.device('cuda'))\n",
    "            y.to(torch.device('cuda'))\n",
    "            optimizer.zero_grad()\n",
    "            l = loss(net(X),y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        train_ls.append(log_rmse(net, X, y))\n",
    "        if test_iter is not None:\n",
    "            X,y = next(iter(test_iter))\n",
    "            test_ls.append(log_rmse(net, X, y))\n",
    "        print(f'epoch:{epoch} 训练log rmse: {float(train_ls[-1]):f}, '\n",
    "              f'验证log rmse: {float(test_ls[-1]):f}')\n",
    "    return train_ls,test_ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_ls,test_ls \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m d2l\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)), [train_ls, test_ls],\n\u001b[0;32m      3\u001b[0m                      xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m, xlim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, epochs],\n\u001b[0;32m      4\u001b[0m                      legend\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m], yscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 打印最后一次的结果\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, loss, train_iter, test_iter, num_epochs, optimizer)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X,y \u001b[38;5;129;01min\u001b[39;00m train_iter:\n\u001b[0;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 11\u001b[0m     l \u001b[38;5;241m=\u001b[39m loss(\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m,y)\n\u001b[0;32m     12\u001b[0m     l\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     13\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\d2l-zh\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\d2l-zh\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\d2l-zh\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\d2l-zh\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ls,test_ls = train(net,loss,train_dataset,test_dataset,num_epochs=epochs,optimizer=optimizer)\n",
    "d2l.plot(list(range(1, epochs + 1)), [train_ls, test_ls],\n",
    "                     xlabel='epoch', ylabel='rmse', xlim=[1, epochs],\n",
    "                     legend=['train', 'valid'], yscale='log')\n",
    "# 打印最后一次的结果\n",
    "print(f'训练log rmse: {float(train_ls[-1]):f}, '\n",
    "              f'验证log rmse: {float(test_ls[-1]):f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        124187.289062\n",
      "1        110984.312500\n",
      "2        124187.289062\n",
      "3        124187.289062\n",
      "4        110984.312500\n",
      "             ...      \n",
      "31621    154339.109375\n",
      "31622    100998.132812\n",
      "31623    183742.843750\n",
      "31624    110984.312500\n",
      "31625    107980.156250\n",
      "Name: Sold Price, Length: 31626, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "test_data_tensor = torch.tensor(valid_data.fillna(0).astype(int).values,dtype=torch.float32)\n",
    "preds = net(test_data_tensor).detach().numpy() # 预测结果\n",
    "test_data['Sold Price'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "print(test_data['Sold Price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "submission = pd.concat([test_data['Id'],test_data['Sold Price']],axis=1)\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-zh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
